---
title: "Statistical Inference"
author: "Evgeniia Golovina"
date: "24/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results="hide")
```

## Statistical Inference course (Coursera)

Week 1 Quiz

```{r week_1_quiz}
# Q1 - 11%
# Q2 - 0.75
# Q3 - p/(1-p) = Y/X
# Q4 - The median must be 0
# Q5 - 3
# Q6 - 40%
```

Week 2 Quiz

```{r week_2_quiz}
# Q1 - Ïƒ^2/n
# Q2 - How many sds below the mean 70 is? (70-80)/10 = -1;pnorm(-1) = ~16%
# Q3 - qnorm(.95, mean = 1100, sd = 75) = ~1223
# Q4 - qnorm(0.95, mean = 1100, sd = 75/sqrt(100)) ~1112
# Q5 - pbinom(3, size = 5, prob = 0.5, lower.tail = FALSE) 0.1875
# Q6 - pnorm(16, mean = 15, sd = 1) - pnorm(14, mean = 15, sd = 1) 0.6827
# Q7 - According to the LLN it should be near .5
# Q8 - ppois(10, lambda = 5*3) 0.1185
```

Week 3

```{r w3}
# comparing the t and Z distributions
library(manipulate)
k <- 1000
xvals <- seq(-5, 5, length = k)
myplot <- function(df){
  d <- data.frame(y = c(dnorm(xvals), dt(xvals, df)),
                  x = xvals,
                  dist = factor(rep(c("Normal", "T"), c(k,k))))
  g <- ggplot(d, aes(x = x, y = y))
  g <- g + geom_line(size = 2, aes(color = dist))
  g
}
manipulate(myplot(mu), mu = slider(1, 20, step = 1)) # t distribution has thicker or heavier tails

# comparing the upper quantiles of the t and Z densities
pvals <- seq(.5, .99, by = .01)
myplot2 <- function(df){
  d <- data.frame(n= qnorm(pvals),t=qt(pvals, df),
                  p = pvals)
  g <- ggplot(d, aes(x= n, y = t))
  g <- g + geom_abline(size = 2, col = "lightblue")
  g <- g + geom_line(size = 2, col = "black")
  g <- g + geom_vline(xintercept = qnorm(0.975))
  g <- g + geom_hline(yintercept = qt(0.975, df))
  g
}
manipulate(myplot2(df), df = slider(1, 20, step = 1)) # t intervals will be always wider that Z intervals

# t confidence intervals example
data(sleep); head(sleep)
# paired observations are connected with a line; comparing subject specific differences when comparing acros the groups not the variations bwteen groups
g1 <- sleep$extra[1:10]; g2 <- sleep$extra[11:20]
difference <- g2 - g1
mn <- mean(difference); s <- sd(difference); n <- 10
# calculating 95% t confidence interval directly
mn + c(-1, 1) * qt(.975, n-1)*s/sqrt(n)
# using R's built in function
t.test(difference)
# using R's built in function, another format
t.test(g2, g1, paired = TRUE)
# using R's built in function, another format
t.test(extra ~ I(relevel(group, 2)), paired = TRUE, data = sleep)

# estimating pooled variance: comparing SBP for 8 oral contraceptive users (X) versus 21 controls (Y); mean of X is 132.86, sd of X is 15.34; mean of Y is 127.44, sd of Y is 18.23
sp <- sqrt((7*15.34^2 + 20 * 18.23^2)/(8 + 21 - 2))
132.86 - 127.44 + c(-1,1) * qt(.975, 27) * sp * (1 / 8 + 1 / 20)^.5 # independent group t interval

# mistakenly treating the sleep data as grouped: different intervals for grouped vs paired! Because intersubject variability exusts!
n1 <- length(g1); n2 <- length(g2)
sp <- sqrt( ((n1 - 1) * sd(x1)^2 + (n2-1) * sd(x2)^2) / (n1 + n2-2))
md <- mean(g2) - mean(g1)
semd <- sp * sqrt(1 / n1 + 1/n2)
rbind(md + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd,
      t.test(g2, g1, paired = FALSE, var.equal = TRUE)$conf,
      t.test(g2, g1, paired = TRUE)$conf
)

# ChickWeight example
library(datasets); data(ChickWeight); library(reshape2); library(dplyr)
# defining weight gain or loss
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1 : 2)] <- paste("time", names(wideCW)[-(1 : 2)], sep = "")
wideCW <- mutate(wideCW, gain = time21 - time0)
# calculating t intervals
wideCW14 <- subset(wideCW, Diet %in% c(1, 4))
rbind(t.test(gain ~ Diet, paired = FALSE, var.equal = TRUE, data = wideCW14)$conf,
      t.test(gain ~ Diet, paired = FALSE, var.equal = FALSE, data = wideCW14)$conf
)

# t test
library(UsingR); data(father.son)
t.test(father.son$sheight - father.son$fheight)
# One Sample t-test
#data: father.son$sheight - father.son$fheight
#t = 11.79, df = 1077, p-value < 2.2e-16
#alternative hypothesis: true mean is not equal to 0
#95 percent confidence interval:
#0.831 1.163
#sample estimates:
#mean of x
#0.997

# two group confidence intervals
library(datasets); data(ChickWeight); library(reshape2); library(dplyr)
# defining weight gain or loss
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1:2)] <- paste("time", names(wideCW)[-(1:2)], sep = "")
wideCW <- mutate(wideCW, gain = time21 - time0)
# Two sample t-test. Unequal variance T test comparing diets 1 and 4.
wideCW14 <- subset(wideCW, Diet %in% c(1, 4))
t.test(gain ~ Diet, paired = FALSE, var.equal = TRUE, data = wideCW14)
# t = -2.7252 is an estimate that the difference in the average weight gain between the two diets less then hypethisied value 0. t statistics calculates how many standard estimated errors our difference in means is from hypothesised

# p values
pt(2.5, 15, lower.tail = FALSE)
# if each gender has an independent 50% probability for each birth, what's the probability of gettting 7 or more girls out of 8 births?
choose(8,7) * 0.5^8 + choose(8,8) * 0.5^8 # binomial calculations
pbinom(6, size = 8, prob = 0.5, lower.tail = FALSE)
```

Week 3 Homework and Quiz

```{r w3_homework_and_quiz}
## Homework
# Q1
t.test(mtcars$mpg) # 95 percent confidence interval: 17.91768 22.26357
# Q2
n = 9; sd = 1
qt(.975, 8)
y <- qt(.975, 8) * sd/sqrt(9) # 0.768668 for lower endpoint
# Q3 - should be statistically independent
# Q4 - 3.154286 10.687272
head(mtcars)
c4 <- mtcars$mpg[mtcars$cyl==4]; c6 <- mtcars$mpg[mtcars$cyl==6]
t.test(c4, c6, var.equal = TRUE) # 3.154286 10.687272
# Q5 - wide interval is better
# Q6 - the interval is above 0 and 4 is better than 6 in the terms of MPG
# Q7 - 2.745
n1 <- 9; n2 <- 9
sd1 <- 1.5; sd2 <- 1.8
sp <- ((n1-1) * sd1^2 + (n2-1) * sd2^2) / (n1 + n2-2) # 2.745
# Q8 - the proportion of successes
# Q9 - assigning a prior probability distribution

## Quiz
# Q1 - 1077, 1123
qt(.975, 8) # 1.859548
sd <- 30
semd <- sd/sqrt(9) 
1100 + c(-1, 1) * qt(.975, 8) * semd # 1076.94 1123.06
# Q2 - 2.60
y <- -2; n = 9; qt(.975, 8)
qt(.975, 8) * sd/3 = -2; sd <- abs(-6/qt(.975, 8)) # 2.60
# Q3 - a paired interval
# Q4 - -2.751649 -1.248351
# interval for new system
m_new <- 3
sd_new <- sqrt(0.60); s_new = 0.60
semd_new <- sd_new/sqrt(10) 
m_new + c(-1, 1) * qt(.975, 9) * semd_new
# interval for old system
m_old <- 5
sd_old <- sqrt(0.68); s_old <- 0.68
semd_old <- sd_old/sqrt(10) 
m_old + c(-1, 1) * qt(.975, 9) * semd_old
# interval for both
n1 <- 10; n2 <- 10
sp <- sqrt(((n1 - 1) * s_new + (n2-1) * s_old) / (n1 + n2-2))
md <- m_new - m_old
semd <- sp * sqrt(1/n1 + 1/n2)
md + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd # -2.751649 -1.248351
# Q5 - the interval will be narrower
# Q6 - interval is above zero; the new system appears to be effective
# substracting: new - old
n1 <- n2 <- 100; m_new <- 4; m_old <- 6; sd_new <- 0.5; sd_old <- 2
sp <- sqrt(((n1-1) * sd_new^2 + (n2-1) * sd_old^2) / (n1 + n2-2))
md <- m_new - m_old
semd <- sp * sqrt(1/n1 + 1/n2)
md + c(-1, 1) * qt(.975, n1 + n2 - 2) * semd
# calculating degrees of freedom
df <- ((sd_new^4/n1 + sd_old^4/n2)^2)/((((sd_new^4/n1)^2)/(n1-1))+(((sd_old^4/n2)^2)/(n2-1)))
md + c(-1, 1) * qt(.975, df) * semd # -2.409018 -1.590982
# substracting: old - new
n_new <- n_old <- 100; m_new <- 4; m_old <- 6; sd_new <- 0.5; sd_old <- 2
sp <- sqrt(((n_old-1) * sd_old^2 + (n_new-1) * sd_new^2) / (n_old + n_new-2))
md <- m_old - m_new
semd <- sp * sqrt(1/n_old + 1/n_new)
md + c(-1, 1) * qt(.975, n_old + n_new - 2) * semd
# calculating degrees of freedom
df <- ((sd_old^4/n_old + sd_new^4/n_new)^2)/((((sd_old^4/n_old)^2)/(n_old-1))+(((sd_new^4/n_new)^2)/(n_new-1)))
md + c(-1, 1) * qt(.975, df) * semd # 1.590982 2.409018
# Q7 - -5.364, -2,636
n_tr <- n_pl <- 9; m_tr <- -3; m_pl <- 1; sd_tr <- 1.5; sd_pl <- 1.8
sp <- sqrt(((n_tr-1) * sd_tr^2 + (n_pl-1) * sd_pl^2) / (n_tr + n_pl-2))
md <- m_tr - m_pl
semd <- sp * sqrt(1/n_tr + 1/n_pl)
df <- ((sd_tr^4/n_tr + sd_pl^4/n_pl)^2)/((((sd_tr^4/n_tr)^2)/(n_tr-1))+(((sd_pl^4/n_pl)^2)/(n_pl-1)))
md + c(-1, 1) * qt(.95, df) * semd # -5.373856 -2.626144
md + c(-1, 1) * qt(.95, 16) * semd # -5.363579 -2.636421
```

Week 4

```{r w4}
# calculating power for Gaussian dat
alpha = 0.05; z <- qnorm(1 - alpha)
pnorm(mu0 + z*sigma/sqrt(n), mean=mua, sd=sigma/sqrt(n), lower.tail = FALSE)

# example
mu0 = 30; mua = 32; sigma = 4; n = 16; alpha = 0.05
z <- qnorm(1 - alpha)
pnorm(mu0 + z*sigma/sqrt(n), mean=mua, sd=sigma/sqrt(n), lower.tail = FALSE)

# investigating power
library(manipulate)
mu0 = 30
myplot <- function(sigma, mua, n, alpha) {
  g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
  g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mu0,
                                                                sd = sigma/sqrt(n)), size = 2, 
                        col = "red")
  g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mua,
                                                                sd = sigma/sqrt(n)), size = 2, 
                        col = "blue")
  xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
  g = g + geom_vline(xintercept = xitc, size = 3)
  g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial= 4),
           mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1, initial = 16), 
           alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))

# T test power; delta is the difference in the means
# omitting the power and getting a power estimate
power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
# illustrating that it depends only on the effect size which is delta/sd
power.t.test(n = 16, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$power
# same thing again
power.t.test(n = 16, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$power
# specifying the power and getting n
power.t.test(power = 0.8, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$n
# again illustrating that the effect size is all that matters
power.t.test(power = 0.8, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$n
# again illustrating that the effect size is all that matters
power.t.test(power = 0.8, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$n
# specifying the power and n, and getting delta
power.t.test(power = 0.8, n = 100, sd = 1, type = "one.sample", alt = "one.sided")$delta

# Multiple testing
# case study 1: no true positives
set.seed(1234)
pValues <- rep(NA, 1000)
for(i in 1:1000){
  y <- rnorm(20)
  x <- rnorm(20)
  pValues[i] <- summary(lm(y ~ x))$coeff[2,4]
}
sum(pValues < 0.05)
# controlling FWER
sum(p.adjust(pValues, method="bonferroni") < 0.05)
# controlling FDR
sum(p.adjust(pValues, method="BH") < 0.05)

# case study 2: 50% true positives
set.seed(1234)
pValues <- rep(NA, 1000)
for(i in 1:1000){
  y <- rnorm(20)
  if(i <= 500){y <- rnorm(20)}else{y <- rnorm(20, mean=2*x)}
  pValues[i] <- summary(lm(y ~ x))$coeff[2,4]
}
trueStatus <- rep(c("zero", "not_zero"), each=500)
table(pValues < 0.05, trueStatus)
# controlling FWER
sum(p.adjust(pValues, method="bonferroni") < 0.05) # 500 true false positives
table(p.adjust(pValues, method="bonferroni") < 0.05, trueStatus)
# controlling FDR
sum(p.adjust(pValues, method="BH") < 0.05) # 9 extra false positives!
table(p.adjust(pValues, method="BH") < 0.05, trueStatus)

# p-values vs adjusted p-values
par(mfrow=c(1,2))
plot(pValues, p.adjust(pValues, method="bonferroni"), pch=19)
plot(pValues, p.adjust(pValues, method="BH"), pch=19)

# resampling
# bootstrapping
library(UsingR); data(father.son)
x <- father.son$sheight
n <- length(x)
B <- 10000
resamples <- matrix(sample(x, n * B, replace = TRUE), B, n)
resampledMedians <- apply(resamples, 1, median)
# nonparametric bootstrapping
B <- 10000
resamples <- matrix(sample(x, n * B, replace = TRUE), B, n)
medians <- apply(resamples, 1, median)
sd(medians) # calculating stadnard deviations of the medians to estimate standard error of median
quantile(medians, c(.025, .975)) # # percentiles as a confidence interval for median
g = ggplot(data.frame(medians = medians), aes(x = medians))
g = g + geom_histogram(color = "black", fill = "lightblue", binwidth = 0.05)
g

# permutation test
data(InsectSprays)
g = ggplot(InsectSprays, aes(spray, count, fill = spray))
g = g + geom_boxplot()
g
# permutation for groups B and C
subdata <- InsectSprays[InsectSprays$spray %in% c("B", "C"),]
y <- subdata$count
group <- as.character(subdata$spray)
testStat <- function(w, g) mean(w[g=="B"]) - mean(w[g=="C"])
observedStat <- testStat(y, group)
permutations <- sapply(1:10000, function(i) testStat(y, sample(group)))
observedStat
# proportion of times we got a simulated statistic larger than our observed statistic
mean(permutations > observedStat)
```

Week 4 Homework and Quiz

```{r w4_homework_and_quiz}
## Homework
# Q1 - 21.84309
mn <- mean(mtcars$mpg); s <- sd(mtcars$mpg); z <- qnorm(.05)
mu0 <- mn - z*s/sqrt(nrow(mtcars)); mu0
# Q2 - rejecting and p-value = 0.0004048
c4 <- mtcars$mpg[mtcars$cyl==4]; c6 <- mtcars$mpg[mtcars$cyl==6]
t.test(c4, c6, var.equal = FALSE, paired=FALSE, alternative = "two.sided")
# Q3 - 2.784404 3.215596
n <- 100; mn <- 3; sd <- 1.1; semd <- sd/sqrt(n) 
mn + c(-1, 1) * qnorm(.975) * semd # 2.784404 3.215596
# Q4 - rejecting, p-value 0.1841008
# Ho: p=.5 Ha: p>.5
pbinom(54, size=100, prob=.5, lower.tail=FALSE) # 0.1841008
pnorm(.55, mean=.5, sd=sqrt(.5*.5/100), lower.tail=FALSE) # 0.1586553
# Q5 - p-value 0.05533114, 0 - not rejecting Ho
# Ho: mn=520 Ha: mn>520 per day
ppois(15800-1, lambda=520*30, lower.tail=FALSE) # 0.05533114
pnorm(15800, mean=520*30, sd=sqrt(520*30), lower.tail=FALSE) # 0.05465729 for normal approximation
# Q6 - p-value 0.07709987, 1 - for rejecting Ho
# AB test or randomized trial or treatment/control
# Ho: theris no difference so mo=0 Ha: ther is a difference
m1 <- 10; m2 <- 11; md <- 10 - 11; sp <- 4; semn <- 4*sqrt(1/100 + 1/100); mo = 0
z <- (md - mo)/semn; z # how many standard errors away from 0 was our observed difference
pnorm(z)
2 * pnorm(z) # for two-sided test
# Q7 - 0.8037244
# Ho: mu = 10, Ha: mu > 10, n = 100, sd = 4
# m ~ N(10, 4/sqrt(100)) under the Ho
# reject if m > 10 + 1.645* .4 # .4 is a standard error
# m ~ N(11, .4) under Ha
m <- 10 + 1.645* .4
pnorm(m, mean=11, sd=.4, lower.tail = FALSE) # 0.8037244
# Q8 - 99
# Ho: mu=0 Ha: mu>0, sd=0.04, power=80%, mua = 0.01
# m ~ N(0, sd=0.04/sqrt(n)) under Ho
# reject Ho if m > 0 + 1.645*0.04/sqrt(n)
1.645*0.04
n = 10
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 10 power is 0.1853935
n = 1000
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 1000 power is 1
n = 500
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 500 power is 0.9999601
n = 250
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 250 power is 0.9894962
n = 100
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 100 power is 0.8037244
n = 99
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 99 power is 0.8002371
n <- (qnorm(.95) + qnorm(.8))^2 * .04^2/.01^2 # 99
# Q9 - more innocent people will be convicted
# Q10 - 0, 0, 2.27, 1 - for rejecting Ho
m6 <- mtcars$mpg[mtcars$cyl==6]; m8 <- mtcars$mpg[mtcars$cyl==8]
p <- t.test(m6, m8, var.equal = TRUE) # t = 4.419, df = 19, p-value = 0.0002947
2 * pnorm(-4.419) # for z-test, where -4.419 is a negative t statistic
mn6 <- mean(m6); mn8 <- mean(m8)
s6 <- sd(m6); s8 <- sd(m8)
n6 <- length(m6); n8 <- length(m8)
sp <- sqrt(((n6-1)*s6^2 + (n8-1) * s8^2)/(n6 + n8 -2)); sp # 2.269676
z <- (mn6 - mn8)/(sp* sqrt(1/n6 + 1/n8)); z # 4.419009

## Quiz
# Q1 - p-value = 0.08652
base <- c(140,138,150,148,135); tr <- c(132,135,151,146,130)
t.test(base, tr, var.equal = FALSE, paired=TRUE, alternative = "two.sided")
# Q2 - 1077 to 1123
n <- 9; mn <- 1100; sd <- 30; semd <- sd/sqrt(n) 
mn + c(-1, 1) * qnorm(.975) * semd # 1080.4 1119.6
mn + c(-1, 1) * qt(.975, 8) * semd # 1076.94 1123.06 where 8 is degrees of freedom
# Q3 - 0.31
pbinom(2, size=4, prob=.5, lower.tail=FALSE) # 0.3125
# Q4 - 0.03
# Ho: infection rate = 0.01 Ha: infection rate =< 0.01
# lower.tail if TRUE (default), probabilities are P[X â‰¤ x], otherwise, P[X > x].
ppois(10-1, lambda=0.01*1787, lower.tail=TRUE) # 0.01649922
ppois(10, lambda=0.01*1787, lower.tail=TRUE) # 0.03237153
pnorm(10, mean=0.01*1787, sd=sqrt(0.01*1787), lower.tail=TRUE) # 0.03132186 for normal approximation
# Q5 - 3.031546e-07 is less than 0.01
# Ho: theris no difference so mo=0 Ha: ther is a difference
n_tr <- n_pl <- 9; m_tr <- -3; m_pl <- 1; sd_tr <- 1.5; sd_pl <- 1.8
sp <- sqrt(((n_tr-1) * sd_tr^2 + (n_pl-1) * sd_pl^2) / (n_tr + n_pl-2))
semd <- sp * sqrt(1/n_tr + 1/n_pl)
md <- m_tr - m_pl; mo <- 0
z <- (md - mo)/semd; z # how many standard errors away from 0 was our observed difference
pnorm(z)
2 * pnorm(z) # 3.031546e-07 for two-sided test
# Q6 - No you wouldn't reject two-sided 5% hypothesis because 1.078 is within 90% confidence interval of 1077 to 1123
# Q7 - 0.80
# Ho: mu=0 Ha: mu>0, sd=0.04, n=100, mua = 0.01
# m ~ N(0, sd=0.04/sqrt(n)) under Ho
# reject Ho if m > 0 + 1.645*0.04/sqrt(n)
s <- 0.04
n <- 100
pnorm(1.645*s/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 100 power is 0.8037244
# Q8 - 140
# Ho: mu=0 Ha: mu>0, sd=0.04, power=90%, mua = 0.01
# m ~ N(0, sd=0.04/sqrt(n)) under Ho
# reject Ho if m > 0 + 1.645*0.04/sqrt(n)
1.645*0.04
n = 10
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 10 power is 0.1853935
n = 1000
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 1000 power is 1
n = 500
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 500 power is 0.9999601
n = 140
pnorm(0.0658/sqrt(n), mean=0.01, sd=0.04/sqrt(n), lower.tail = F) # if n = 140 power is 0.9054152
n <- (qnorm(.95) + qnorm(.9))^2 * .04^2/.01^2 # 137
# Q9 - increasing alpha will increase the power
```

Week 4 Course Project

```{r w4_course_project}

```


